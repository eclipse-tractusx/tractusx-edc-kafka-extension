#################################################################################
#  Copyright (c) 2025 Contributors to the Eclipse Foundation
#
#  See the NOTICE file(s) distributed with this work for additional
#  information regarding copyright ownership.
#
#  This program and the accompanying materials are made available under the
#  terms of the Apache License, Version 2.0 which is available at
#  https://www.apache.org/licenses/LICENSE-2.0.
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#  WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#  License for the specific language governing permissions and limitations
#  under the License.
#
#  SPDX-License-Identifier: Apache-2.0
#################################################################################
global:
  security:
    # required to use bitnamilegacy images
    allowInsecureImages: true

kafka:
  enabled: true

  # ─── Single‑pod KRaft cluster ────────────────────────────────────────────
  clusterId: "hNz3ciwPTzig3iL9jqyQ9w"
  kraftVersion: 1
  controller:
    replicaCount: 1
    persistence:
      enabled: false

  # ─── Listener matrix ─────────────────────────────────────────────────────
  listeners:
    client:
      protocol: PLAINTEXT
    interbroker:
      protocol: PLAINTEXT
    controller:
      protocol: PLAINTEXT
    external:
      protocol: SASL_PLAINTEXT
      containerPort: 9095

  externalAccess:
    enabled: true
    controller:
      service:
        type: LoadBalancer
        ports:
          external: 9095
        loadBalancerNames:
          # cannot be templated so has to be adjusted manually when using a different release name and/or namespace
          - "demo-kafka.demo.svc.cluster.local"

  # ─── SASL / OAUTHBEARER ──────────────────────────────────────────────────
  sasl:
    enabledMechanisms: OAUTHBEARER,PLAIN
    interBrokerMechanism: PLAIN
    controllerMechanism: PLAIN
    oauthbearer:
      jwksEndpointUrl: "http://{{ .Release.Name }}-keycloak:80/realms/kafka/protocol/openid-connect/certs"
      tokenEndpointUrl: "http://{{ .Release.Name }}-keycloak:80/realms/kafka/protocol/openid-connect/token"
      expectedAudience: "account"

  # ─── Extra broker properties ─────────────────────────────────────────────
  overrideConfiguration:
    # broker‑side validator for JWTs
    listener.name.external.oauthbearer.sasl.server.callback.handler.class: |
      org.apache.kafka.common.security.oauthbearer.OAuthBearerValidatorCallbackHandler
    # single‑node replication tweaks
    offsets.topic.replication.factor: "1"
    transaction.state.log.replication.factor: "1"
    transaction.state.log.min.isr: "1"

  extraEnvVars:
    - name: KAFKA_OPTS
      value: |
        -Dorg.apache.kafka.sasl.oauthbearer.allowed.urls=http://{{ .Release.Name }}-keycloak:80/realms/kafka/protocol/openid-connect/certs,http://{{ .Release.Name }}-keycloak:80/realms/kafka/protocol/openid-connect/token

keycloak:
  image:
    repository: bitnamilegacy/keycloak
  enabled: true
  auth:
    adminUser: admin
    adminPassword: admin
  extraEnvVars:
    - name: KEYCLOAK_EXTRA_ARGS
      value: "--import-realm"
  extraVolumes:
    - name: realm
      configMap:
        name: "{{ .Release.Name }}-keycloak-realm-config"
  extraVolumeMounts:
      - name: realm
        mountPath: /opt/bitnami/keycloak/data/import
        readOnly: true
  postgresql:
    auth:
      postgresPassword: "test"
      username: bn_keycloak
      password: "test"
      database: bitnami_keycloak
    primary:
      persistence:
        enabled: false
  livenessProbe:
    initialDelaySeconds: 120
    periodSeconds: 1
    timeoutSeconds: 5
    failureThreshold: 10
  readinessProbe:
    initialDelaySeconds: 30
    periodSeconds: 5
    timeoutSeconds: 1
    failureThreshold: 10

consumer-app:
  enabled: true
  secrets:
    edcApiKey: "password"
  application:
    # EDC Configuration
    edc:
      managementUrl: "http://{{ .Release.Name }}-consumer-edc-controlplane:8081/management"
      assets:
        stream: "kafka-stream-asset"
        forecast: "kafka-forecast-asset"
        tracking: "kafka-tracking-asset"

    # Provider Configuration
    provider:
      id: "BPNL000000000B02"
      protocolUrl: "http://{{ .Release.Name }}-producer-edc-controlplane:8084/api/v1/dsp"

producer-app:
  enabled: true
  application:
    kafka:
      bootstrapServers: "{{ .Release.Name }}-kafka-controller-0-external:9095"
      topics:
        productionForecast: "kafka-production-forecast-topic"
        productionTracking: "kafka-production-tracking-topic"
        stream: "kafka-stream-topic"

    authentication:
      oauth2:
        clientId: "myclient"
        tokenUrl: "http://{{ .Release.Name }}-keycloak:80/realms/kafka/protocol/openid-connect/token"
        revokeUrl: "http://{{ .Release.Name }}-keycloak:80/realms/kafka/protocol/openid-connect/revoke"

    edc:
      managementUrl: "http://{{ .Release.Name }}-producer-edc-controlplane:8081/management"
      assets:
        stream: "kafka-stream-asset"
        forecast: "kafka-forecast-asset"
        tracking: "kafka-tracking-asset"

  secrets:
    oauth2ClientSecret: "mysecret"
    clientSecretVaultKey: "secretKey"
    edcApiAuthKey: "password"

producer-edc:
  enabled: true
  tractusx-connector:
    nameOverride: producer-edc
    postgresql:
      nameOverride: producer-edc-posgresql
      jdbcUrl: "jdbc:postgresql://{{ .Release.Name }}-producer-edc-posgresql:5432/edc"
    participant:
      id: "BPNL000000000B02"
    iatp:
      id: "did:web:changeme"
      trustedIssuers: []
      sts:
        dim:
          url: http://test.local
        oauth:
          token_url: http://test.local
          client:
            id: clientId
            secret_alias: clientSecretAlias
    controlplane:
      image:
        # override the edc docker image with the kafka extension image
        repository: "edc-controlplane-kafka-local"
        pullPolicy: IfNotPresent
        tag: "latest"
      endpoints:
        management:
          authKey: "password"
      bdrs:
        server:
          url: http://test.local
    dataplane:
      image:
        # override the edc docker image with the kafka extension image
        repository: "edc-dataplane-kafka-local"
        pullPolicy: IfNotPresent
        tag: "latest"
      token:
        signer:
          privatekey_alias: tokenSignerPrivateKey
        verifier:
          publickey_alias: tokenSignerPublicKey

consumer-edc:
  enabled: true
  tractusx-connector:
    install:
      vault: false
    nameOverride: consumer-edc
    postgresql:
      nameOverride: consumer-edc-posgresql
      jdbcUrl: "jdbc:postgresql://{{ .Release.Name }}-consumer-edc-posgresql:5432/edc"
    participant:
      id: "BPNL000000000A01"
    iatp:
      id: "did:web:changeme"
      trustedIssuers: []
      sts:
        dim:
          url: http://test.local
        oauth:
          token_url: http://test.local
          client:
            id: clientId
            secret_alias: clientSecretAlias
    controlplane:
      image:
        # override the edc docker image with the kafka extension image
        repository: "edc-controlplane-kafka-local"
        pullPolicy: IfNotPresent
        tag: "latest"
      endpoints:
        management:
          authKey: "password"
      bdrs:
        server:
          url: http://test.local
    dataplane:
      image:
        # override the edc docker image with the kafka extension image
        repository: "edc-dataplane-kafka-local"
        pullPolicy: IfNotPresent
        tag: "latest"
      token:
        signer:
          privatekey_alias: tokenSignerPrivateKey
        verifier:
          publickey_alias: tokenSignerPublicKey
